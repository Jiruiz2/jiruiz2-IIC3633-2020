# Crítica: Multi-Armed Recommender System Bandit Ensembles

Se ha demostrado que los ensambles de sistemas recomendadores logran una mayor efectividad a la hora de realizar recomendaciones que los sistemas por separado. Por esto es que se han desarrollado muchos estudios para poder optimizar de forma automática la configuración de estos ensambles. Sin embargo, la mayoría del trabajo en esta área se realiza en base a escenarios simplificados y estáticos en lugar de dinámicos y cambiantes. Es por esto que los autores consideran una perspectiva más realista donde toman en cuenta el ciclo natural de una recomendación utilizando las reacciones de los usuarios sobre las recomendaciones que reciben. Por lo anterior, es que los autores adaptan un enfoque que utiliza un modelo de "Bandido Multibrazo" buscando maximizar las recompensas (recomendaciones efectivas) actualizando los brazos que se utilicen (algoritmos de recomendación). Por último, es importante señalar que los resultados demostraron que la efectividad del enfoque ofrecido por los autores supera a otra opciones de ensambles en la industria.

Considero que es importante el uso de escenarios establecidos y estáticos para poder probar algoritmos y poder tener un acercamiento sobre el desempeño que este puede tener al tratar con usuarios reales. Sin embargo, el mundo real es sumamente dinámico, y no tenerlo en cuenta puede significar que el algoritmo tenga un peor resultado al esperado.

Por su parte, el uso de un proceso cíclico significa un mayor tiempo de entrenamiento para un algoritmo, ya que puede ocurrir que este demore en converger a un resultado concreto. Sin embargo, permite conseguir un mejor desempeño, debido a que en cada iteración realiza un testeo del ensamble y mejora su configuración.

Por otro lado, el hecho de agregar dinamismo a las recomendaciones, es decir, probarlas en ambientes cambiantes significa un aumento en el tiempo de ejecución del mismo, por lo que muchos ensambles se ven impedidos de ser utilizados en un ambiente de produccción independiente de su efectividad.

Me hubiese gustado que se tomaran un tiempo para explicar en que consisten las técnicas de bandido, ya que no se menciona como trabajo relacionado y termina por complicar el entendimiento de la lectura. Lo mismo aplica para los algoritmos bandidos que decidieron utilizar, ya que, si bien explicaron como funcionan, no mostraron las fórmulas que los guían, por lo que es difícil entender cómo afectan las variables que quieren configurar.

Me parece interesante el uso de técnicas de "Bandido Multibrazo" para crear ensambles de sistemas recomendadores y con ello obtener una configuración ideal para estos, ya que es un algoritmo que permite maximizar la recompensa obtenida (recomendaciones correctas) y a su vez actualizar los brazos utilizados (algoritmos de recomendación) en cada iteración que se realice para entrenarlo.

Por último, considero que cómo trabajo futuro se debería buscar comparar la propuesta de los autores con algoritmos que tengan un mejor desempeño a los que testearon, ya que estos han sido constantemente superados en la literatura. Si bien, es un buen punto de partida, considero que se debe realizar lo sugerido para demostrar de manera definitiva el avance que ofrece la solución de los autores.